# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lmDPXVgnnEME28bujuHPMeZ4OKDdmEVi
"""

#from google.colab import drive
#drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import plot_roc_curve

from sklearn.naive_bayes import MultinomialNB  # NB
from sklearn.neighbors import KNeighborsClassifier  # k-NN
from sklearn.linear_model import SGDClassifier  # logistic regression
from sklearn.tree import DecisionTreeClassifier  # DT
from sklearn.svm import LinearSVC  # linear SVM
from sklearn.neural_network import MLPClassifier

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV, PredefinedSplit
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier


plt.style.use('fivethirtyeight')

insurance_data=pd.read_csv('data/insurance.csv')

"""Data cleansing"""

insurance_data.info()

insurance_data.isnull().any()

insurance_data.sex.unique()

insurance_data['bmi_int'] = insurance_data['bmi'].apply(lambda x: int(x))
variables = ['sex','smoker','region','age','bmi_int','children']

# data distribution analysys
print('Data distribution analysys')
for v in variables:
    insurance_data = insurance_data.sort_values(by=[v])
    insurance_data[v].value_counts().plot(kind = 'bar')
    plt.title(v)
    plt.show()

correlation = insurance_data.corr()
correlation

plt.figure(figsize=(8,6))
sns.heatmap(correlation, annot = True)

"""makes a coy of original data to test two models without having errors"""

ols_data=insurance_data

import copy
data= copy.copy(ols_data)

data.sex.replace({'male':1,'female':0},inplace=True)
data.smoker.replace({'yes':1,'no':0},inplace=True)

data.head(10)

data["region"] = insurance_data.region.replace({'southeast':1,'southwest':2,'northwest':3,'northeast':4})

"""one least square regression to show estimate of what patients will pay based on age , sex, region"""

import statsmodels.api as sm
from sklearn.model_selection import train_test_split
X1=data.drop(columns='expenses')
y1=data[['expenses']]
train_X1, test_X1, train_y1, test_y1 = train_test_split(X1,y1,test_size=0.4)
Fake = sm.add_constant(X1)
model = sm.OLS(y1,X1)
results = model.fit()
print(results.summary())

insurance_data.head(10)

"""using extra tree regression for prediction based on the user input"""

from sklearn.ensemble import ExtraTreesRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import sklearn.metrics
import warnings

print('Model training and evaluating\n\n')
#transform categorical data
le_sex = LabelEncoder()
le_smoker = LabelEncoder()
le_region = LabelEncoder()

insurance_data['sex'] = le_sex.fit_transform(insurance_data['sex'])
insurance_data['smoker'] = le_smoker.fit_transform(insurance_data['smoker'])
insurance_data['region'] = le_region.fit_transform(insurance_data['region'])

variables = ['sex','smoker','region','age','bmi','children']

X = insurance_data[variables]
sc = StandardScaler()
X = sc.fit_transform(X) 
Y = insurance_data['expenses']
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)

#train model
regressor = ExtraTreesRegressor(n_estimators = 200)
regressor.fit(X_train,y_train)

#prediction and evaluation
y_train_pred = regressor.predict(X_train)
y_test_pred = regressor.predict(X_test)

print('ExtraTreesRegressor evaluating result:')
print("Train MAE: ", sklearn.metrics.mean_absolute_error(y_train, y_train_pred))
print("Train RMSE: ", np.sqrt(sklearn.metrics.mean_squared_error(y_train, y_train_pred)))
print("Test MAE: ", sklearn.metrics.mean_absolute_error(y_test, y_test_pred))
print("Test RMSE: ", np.sqrt(sklearn.metrics.mean_squared_error(y_test, y_test_pred)))

import pickle
filename = 'Variables_X'
outfile = open(filename,'wb')
pickle.dump(X,outfile)
outfile.close()

filename = 'Expense_Y'
outfile = open(filename,'wb')
pickle.dump(Y,outfile)
outfile.close()

y_test.head(5)

y_train.head(5)

print('Feature importance ranking\n\n')
importances = regressor.feature_importances_
std = np.std([tree.feature_importances_ for tree in regressor.estimators_],axis=0)
indices = np.argsort(importances)[::-1]

importance_list = []
for f in range(X.shape[1]):
    variable = variables[indices[f]]
    importance_list.append(variable)
    print("%d.%s(%f)" % (f + 1, variable, importances[indices[f]]))

print('Predicting on new data\n\n')

billy = ['male','yes','southeast',25,30.5,2]
print('Billy - ',str(billy))

billy[0] = le_sex.transform([billy[0]])[0] 
billy[1] = le_smoker.transform([billy[1]])[0] 
billy[2] = le_region.transform([billy[2]])[0] 

X = sc.transform([billy])

cost_for_billy = regressor.predict(X)[0]
print('Cost for Billy = ',cost_for_billy,'\n\n')


dennis = ['female','no','southeast',45,19,0]
print('Dennis - ',str(dennis))

dennis[0] = le_sex.transform([dennis[0]])[0] 
dennis[1] = le_smoker.transform([dennis[1]])[0] 
dennis[2] = le_region.transform([dennis[2]])[0] 

X = sc.transform([dennis])

cost_for_dennis = regressor.predict(X)[0]

print('Cost for Dennis = ',cost_for_dennis)

y_train.to_csv("train.csv",index=False)
y_test.to_csv("test.csv",index=False)